tensorflow/tensorflow.sh
[tensorflow] 
[tensorflow] == tensorflow unit test ==
Reading package lists...
Building dependency tree...
Reading state information...
wget is already the newest version (1.19.4-1ubuntu2.2).
The following packages were automatically installed and are no longer required:
  libopts25 sntp
Use 'sudo apt autoremove' to remove them.
0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.
[tensorflow] [INFO] Test docker hub official image first:
[tensorflow] 
Get:1 http://security.ubuntu.com/ubuntu xenial-security InRelease [109 kB]
Hit:2 http://archive.ubuntu.com/ubuntu xenial InRelease
Get:3 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [857 kB]
Get:4 http://archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB]
Get:5 http://archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB]
Get:6 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [557 kB]
Get:7 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 Packages [6113 B]
Get:8 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages [1250 kB]
Get:9 http://archive.ubuntu.com/ubuntu xenial-updates/universe amd64 Packages [968 kB]
Get:10 http://archive.ubuntu.com/ubuntu xenial-updates/multiverse amd64 Packages [19.1 kB]
Fetched 3982 kB in 4s (818 kB/s)
Reading package lists...
Reading package lists...
Building dependency tree...
Reading state information...
The following additional packages will be installed:
  libidn11
The following NEW packages will be installed:
  libidn11 wget
0 upgraded, 2 newly installed, 0 to remove and 16 not upgraded.
Need to get 345 kB of archives.
After this operation, 1151 kB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libidn11 amd64 1.32-3ubuntu1.2 [46.5 kB]
Get:2 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 wget amd64 1.17.1-1ubuntu1.5 [299 kB]
Fetched 345 kB in 1s (190 kB/s)
Selecting previously unselected package libidn11:amd64.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 13870 files and directories currently installed.)
Preparing to unpack .../libidn11_1.32-3ubuntu1.2_amd64.deb ...
Unpacking libidn11:amd64 (1.32-3ubuntu1.2) ...
Selecting previously unselected package wget.
Preparing to unpack .../wget_1.17.1-1ubuntu1.5_amd64.deb ...
Unpacking wget (1.17.1-1ubuntu1.5) ...
Processing triggers for libc-bin (2.23-0ubuntu11) ...
Setting up libidn11:amd64 (1.32-3ubuntu1.2) ...
Setting up wget (1.17.1-1ubuntu1.5) ...
Processing triggers for libc-bin (2.23-0ubuntu11) ...
cifar10/
cifar10/cifar10_train.py
cifar10/cifar10_multi_gpu_train.py
cifar10/cifar10_input_test.py
cifar10/cifar10_input.py
cifar10/cifar10_eval.py
cifar10/cifar10.py
cifar10/__init__.py
cifar10/README.md
cifar10/BUILD
cifar-10-batches-bin/
cifar-10-batches-bin/data_batch_1.bin
cifar-10-batches-bin/batches.meta.txt
cifar-10-batches-bin/data_batch_3.bin
cifar-10-batches-bin/data_batch_4.bin
cifar-10-batches-bin/test_batch.bin
cifar-10-batches-bin/readme.html
cifar-10-batches-bin/data_batch_5.bin
cifar-10-batches-bin/data_batch_2.bin

WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2019-06-12 04:48:48.596128: step 0, loss = 4.68 (321.6 examples/sec; 0.398 sec/batch)
2019-06-12 04:48:50.059208: step 10, loss = 4.56 (933.9 examples/sec; 0.137 sec/batch)
2019-06-12 04:48:51.424428: step 20, loss = 4.51 (933.3 examples/sec; 0.137 sec/batch)
2019-06-12 04:48:52.780417: step 30, loss = 4.39 (922.5 examples/sec; 0.139 sec/batch)
2019-06-12 04:48:54.127490: step 40, loss = 4.46 (973.9 examples/sec; 0.131 sec/batch)
2019-06-12 04:48:55.477005: step 50, loss = 4.30 (943.4 examples/sec; 0.136 sec/batch)
2019-06-12 04:48:56.827510: step 60, loss = 4.20 (984.4 examples/sec; 0.130 sec/batch)
2019-06-12 04:48:58.188535: step 70, loss = 4.25 (940.7 examples/sec; 0.136 sec/batch)
2019-06-12 04:48:59.551782: step 80, loss = 4.31 (946.3 examples/sec; 0.135 sec/batch)
2019-06-12 04:49:00.905177: step 90, loss = 4.24 (961.9 examples/sec; 0.133 sec/batch)
2019-06-12 04:49:02.344754: step 100, loss = 4.03 (579.6 examples/sec; 0.221 sec/batch)
2019-06-12 04:49:03.689058: step 110, loss = 4.26 (964.2 examples/sec; 0.133 sec/batch)
2019-06-12 04:49:05.051967: step 120, loss = 4.09 (972.6 examples/sec; 0.132 sec/batch)
2019-06-12 04:49:06.396934: step 130, loss = 4.11 (938.4 examples/sec; 0.136 sec/batch)
2019-06-12 04:49:07.741657: step 140, loss = 4.01 (960.7 examples/sec; 0.133 sec/batch)
2019-06-12 04:49:09.072914: step 150, loss = 3.91 (973.6 examples/sec; 0.131 sec/batch)
2019-06-12 04:49:10.405798: step 160, loss = 3.82 (961.4 examples/sec; 0.133 sec/batch)
2019-06-12 04:49:11.760692: step 170, loss = 4.00 (942.3 examples/sec; 0.136 sec/batch)
2019-06-12 04:49:13.124412: step 180, loss = 3.87 (947.2 examples/sec; 0.135 sec/batch)
2019-06-12 04:49:14.460196: step 190, loss = 3.82 (937.9 examples/sec; 0.136 sec/batch)
2019-06-12 04:49:15.897742: step 200, loss = 3.71 (558.0 examples/sec; 0.229 sec/batch)
2019-06-12 04:49:17.242206: step 210, loss = 4.11 (953.2 examples/sec; 0.134 sec/batch)
2019-06-12 04:49:18.591599: step 220, loss = 3.67 (956.2 examples/sec; 0.134 sec/batch)
2019-06-12 04:49:19.937209: step 230, loss = 3.79 (930.1 examples/sec; 0.138 sec/batch)
2019-06-12 04:49:21.285836: step 240, loss = 3.70 (941.2 examples/sec; 0.136 sec/batch)
2019-06-12 04:49:22.632216: step 250, loss = 3.55 (965.6 examples/sec; 0.133 sec/batch)
2019-06-12 04:49:23.984725: step 260, loss = 3.61 (937.4 examples/sec; 0.137 sec/batch)
2019-06-12 04:49:25.341453: step 270, loss = 3.61 (932.3 examples/sec; 0.137 sec/batch)
2019-06-12 04:49:26.670478: step 280, loss = 3.61 (947.1 examples/sec; 0.135 sec/batch)
2019-06-12 04:49:28.023580: step 290, loss = 3.85 (960.8 examples/sec; 0.133 sec/batch)
2019-06-12 04:49:29.451150: step 300, loss = 3.38 (599.0 examples/sec; 0.214 sec/batch)
2019-06-12 04:49:30.800185: step 310, loss = 3.47 (971.3 examples/sec; 0.132 sec/batch)
2019-06-12 04:49:32.144085: step 320, loss = 3.66 (957.7 examples/sec; 0.134 sec/batch)
2019-06-12 04:49:33.471404: step 330, loss = 3.45 (948.7 examples/sec; 0.135 sec/batch)
2019-06-12 04:49:34.825561: step 340, loss = 3.58 (934.6 examples/sec; 0.137 sec/batch)
2019-06-12 04:49:36.176998: step 350, loss = 3.44 (939.6 examples/sec; 0.136 sec/batch)
2019-06-12 04:49:37.529268: step 360, loss = 3.58 (973.2 examples/sec; 0.132 sec/batch)
2019-06-12 04:49:38.871470: step 370, loss = 3.78 (943.8 examples/sec; 0.136 sec/batch)
2019-06-12 04:49:40.220200: step 380, loss = 3.45 (983.4 examples/sec; 0.130 sec/batch)
2019-06-12 04:49:41.576722: step 390, loss = 3.34 (950.4 examples/sec; 0.135 sec/batch)
Total duration: 54.16 seconds
Default-Tensorflow-Server
[tensorflow] [INFO] Test clear docker image:
[tensorflow] 
Set upstream mirror to https://cdn-alt.download.clearlinux.org/update
Installed version: 29820
Version URL:       https://cdn-alt.download.clearlinux.org/update
Content URL:       https://cdn-alt.download.clearlinux.org/update
Loading required manifests...
Downloading packs (1.02 Mb) for:
 - wget
 - openssl
	...1%
	...3%
	...4%
	...6%
	...7%
	...9%
	...11%
	...12%
	...14%
	...15%
	...17%
	...19%
	...20%
	...22%
	...24%
	...25%
	...27%
	...28%
	...30%
	...32%
	...33%
	...35%
	...36%
	...38%
	...40%
	...41%
	...43%
	...44%
	...46%
	...48%
	...49%
	...51%
	...53%
	...54%
	...56%
	...57%
	...59%
	...61%
	...62%
	...64%
	...65%
	...67%
	...69%
	...70%
	...72%
	...73%
	...75%
	...77%
	...78%
	...80%
	...82%
	...83%
	...85%
	...86%
	...88%
	...90%
	...91%
	...93%
	...94%
	...96%
	...98%
	...99%
	...100%

Finishing packs extraction...
No extra files need to be downloaded
Installing bundle(s) files...
	...1%
	...2%
	...3%
	...4%
	...5%
	...6%
	...7%
	...8%
	...10%
	...11%
	...12%
	...13%
	...14%
	...15%
	...16%
	...17%
	...18%
	...20%
	...21%
	...22%
	...23%
	...24%
	...25%
	...26%
	...27%
	...28%
	...30%
	...31%
	...32%
	...33%
	...34%
	...35%
	...36%
	...37%
	...38%
	...40%
	...41%
	...42%
	...43%
	...44%
	...45%
	...46%
	...47%
	...48%
	...50%
	...51%
	...52%
	...53%
	...54%
	...55%
	...56%
	...57%
	...58%
	...60%
	...61%
	...62%
	...63%
	...64%
	...65%
	...66%
	...67%
	...68%
	...70%
	...71%
	...72%
	...73%
	...74%
	...75%
	...76%
	...77%
	...78%
	...80%
	...81%
	...82%
	...83%
	...84%
	...85%
	...86%
	...87%
	...88%
	...90%
	...91%
	...92%
	...93%
	...94%
	...95%
	...96%
	...97%
	...98%
	...100%

Calling post-update helper scripts.
Successfully installed 1 bundle
cifar10/
cifar10/cifar10_train.py
cifar10/cifar10_multi_gpu_train.py
cifar10/cifar10_input_test.py
cifar10/cifar10_input.py
cifar10/cifar10_eval.py
cifar10/cifar10.py
cifar10/__init__.py
cifar10/README.md
cifar10/BUILD
cifar-10-batches-bin/
cifar-10-batches-bin/data_batch_1.bin
cifar-10-batches-bin/batches.meta.txt
cifar-10-batches-bin/data_batch_3.bin
cifar-10-batches-bin/data_batch_4.bin
cifar-10-batches-bin/test_batch.bin
cifar-10-batches-bin/readme.html
cifar-10-batches-bin/data_batch_5.bin
cifar-10-batches-bin/data_batch_2.bin

WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2019-06-12 04:50:01.566555: step 0, loss = 4.68 (124.8 examples/sec; 1.026 sec/batch)
2019-06-12 04:50:02.630732: step 10, loss = 4.63 (1320.7 examples/sec; 0.097 sec/batch)
2019-06-12 04:50:03.576513: step 20, loss = 4.37 (1334.3 examples/sec; 0.096 sec/batch)
2019-06-12 04:50:04.521624: step 30, loss = 4.46 (1284.3 examples/sec; 0.100 sec/batch)
2019-06-12 04:50:05.458039: step 40, loss = 4.45 (1373.0 examples/sec; 0.093 sec/batch)
2019-06-12 04:50:06.382135: step 50, loss = 4.23 (1343.0 examples/sec; 0.095 sec/batch)
2019-06-12 04:50:07.295340: step 60, loss = 4.33 (1432.9 examples/sec; 0.089 sec/batch)
2019-06-12 04:50:08.207685: step 70, loss = 4.17 (1451.8 examples/sec; 0.088 sec/batch)
2019-06-12 04:50:09.121607: step 80, loss = 4.04 (1406.4 examples/sec; 0.091 sec/batch)
2019-06-12 04:50:10.054409: step 90, loss = 4.15 (1400.8 examples/sec; 0.091 sec/batch)
2019-06-12 04:50:11.083522: step 100, loss = 4.09 (623.3 examples/sec; 0.205 sec/batch)
2019-06-12 04:50:12.005924: step 110, loss = 4.09 (1422.0 examples/sec; 0.090 sec/batch)
2019-06-12 04:50:12.915809: step 120, loss = 4.05 (1399.7 examples/sec; 0.091 sec/batch)
2019-06-12 04:50:13.826348: step 130, loss = 4.08 (1368.5 examples/sec; 0.094 sec/batch)
2019-06-12 04:50:14.754280: step 140, loss = 3.91 (1364.7 examples/sec; 0.094 sec/batch)
2019-06-12 04:50:15.668849: step 150, loss = 3.96 (1419.6 examples/sec; 0.090 sec/batch)
2019-06-12 04:50:16.586025: step 160, loss = 4.06 (1435.3 examples/sec; 0.089 sec/batch)
2019-06-12 04:50:17.508532: step 170, loss = 4.03 (1415.4 examples/sec; 0.090 sec/batch)
2019-06-12 04:50:18.436650: step 180, loss = 4.05 (1316.6 examples/sec; 0.097 sec/batch)
2019-06-12 04:50:19.355674: step 190, loss = 3.77 (1376.1 examples/sec; 0.093 sec/batch)
2019-06-12 04:50:20.368635: step 200, loss = 3.79 (659.1 examples/sec; 0.194 sec/batch)
2019-06-12 04:50:21.286693: step 210, loss = 3.78 (1414.0 examples/sec; 0.091 sec/batch)
2019-06-12 04:50:22.216113: step 220, loss = 3.89 (1327.9 examples/sec; 0.096 sec/batch)
2019-06-12 04:50:23.130133: step 230, loss = 3.89 (1409.9 examples/sec; 0.091 sec/batch)
2019-06-12 04:50:24.039517: step 240, loss = 3.69 (1421.5 examples/sec; 0.090 sec/batch)
2019-06-12 04:50:24.953968: step 250, loss = 3.59 (1444.3 examples/sec; 0.089 sec/batch)
2019-06-12 04:50:25.882021: step 260, loss = 3.73 (1329.3 examples/sec; 0.096 sec/batch)
2019-06-12 04:50:26.803574: step 270, loss = 3.72 (1433.5 examples/sec; 0.089 sec/batch)
2019-06-12 04:50:27.728029: step 280, loss = 3.60 (1453.8 examples/sec; 0.088 sec/batch)
2019-06-12 04:50:28.651693: step 290, loss = 3.64 (1443.8 examples/sec; 0.089 sec/batch)
2019-06-12 04:50:29.673245: step 300, loss = 3.53 (642.9 examples/sec; 0.199 sec/batch)
2019-06-12 04:50:30.597172: step 310, loss = 3.75 (1407.2 examples/sec; 0.091 sec/batch)
2019-06-12 04:50:31.516115: step 320, loss = 3.52 (1419.1 examples/sec; 0.090 sec/batch)
2019-06-12 04:50:32.431411: step 330, loss = 3.50 (1430.8 examples/sec; 0.089 sec/batch)
2019-06-12 04:50:33.339562: step 340, loss = 3.49 (1366.8 examples/sec; 0.094 sec/batch)
2019-06-12 04:50:34.252551: step 350, loss = 3.40 (1406.7 examples/sec; 0.091 sec/batch)
2019-06-12 04:50:35.155653: step 360, loss = 3.44 (1414.1 examples/sec; 0.091 sec/batch)
2019-06-12 04:50:36.082441: step 370, loss = 3.58 (1360.2 examples/sec; 0.094 sec/batch)
2019-06-12 04:50:37.001213: step 380, loss = 3.43 (1397.6 examples/sec; 0.092 sec/batch)
2019-06-12 04:50:37.907506: step 390, loss = 3.29 (1411.6 examples/sec; 0.091 sec/batch)
Total duration: 37.13 seconds
Clr-Tensorflow-Server
